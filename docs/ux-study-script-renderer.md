# UX Study: Script-to-Audiobook Renderer

## Problem

We have:
- **Voice Studio** with character templates (approved voice+emotion combos with audio references)
- **Novel chapters** as annotated markdown (`@speaker`, `@emotion`, text segments)
- A **TTS backend** (Qwen3 VoiceDesign or clone prompts)

We need to connect them: upload a script, match segments to templates, render paragraph-by-paragraph, review, fix, and export a finished chapter audio.

## Current State

The audiobook-render skill (`render_qwen.py`) already:
- Parses annotated markdown into segments (speaker + emotion + text)
- Chunks long segments (500 char max)
- Renders each segment via `/api/v1/voices/design` or clone prompts
- Concatenates to single MP3 via ffmpeg

But it's a CLI tool with zero UI, zero review loop, and hardcoded voice mappings. You render blind and hope it's good.

## Proposed UX Flow

### Screen 1: Script Upload & Parse

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“– Script Renderer                     â”‚
â”‚                                         â”‚
â”‚  [Upload Markdown] or [Paste Text]      â”‚
â”‚                                         â”‚
â”‚  Script: chapter-07.md  âœ… Parsed       â”‚
â”‚  Segments: 47 â”‚ Speakers: 3            â”‚
â”‚  Est. duration: ~8 min                  â”‚
â”‚                                         â”‚
â”‚  [Continue â†’]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Upload an annotated markdown file. System parses into segments with speaker/emotion/text. Shows summary. Supports both annotated (`@speaker`/`@emotion` comments) and plain markdown (auto-detect dialogue vs narration).

### Screen 2: Voice Casting (Template Matching)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸŽ­ Cast Voices                         â”‚
â”‚                                         â”‚
â”‚  narrator (28 segments)                 â”‚
â”‚  â””â”€ Base: [Kira â–¼] template: [calm â–¼]  â”‚
â”‚     Overrides by emotion:               â”‚
â”‚     "tense" â†’ [tense-urgent template â–¼] â”‚
â”‚     "warm"  â†’ [warm-narration template â–¼]â”‚
â”‚     "whisper"â†’ [no match â€” Draft new?]  â”‚
â”‚                                         â”‚
â”‚  maya (12 segments)                     â”‚
â”‚  â””â”€ Base: [Maya â–¼] template: [neutral â–¼]â”‚
â”‚     "excited" â†’ [excited template â–¼]    â”‚
â”‚     "fearful" â†’ [no match â€” Draft new?] â”‚
â”‚                                         â”‚
â”‚  elena (7 segments)                     â”‚
â”‚  â””â”€ [No character match â€” Create?]      â”‚
â”‚                                         â”‚
â”‚  [â—€ Back]            [Cast & Continue â†’] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

System auto-matches speakers to characters and emotions to templates:
1. **Speaker â†’ Character**: Fuzzy match script speaker names to Voice Studio characters
2. **Emotion â†’ Template**: Match `@emotion` tags to approved templates by preset name/type
3. **Gaps shown clearly**: Unmatched emotions offer "Draft new?" (jumps to CharacterPage to create one)
4. **Override per emotion**: User can swap any template assignment

**Matching algorithm:**
- Exact match: `@emotion: happy` â†’ template with `preset_name=happy`
- Fuzzy: `@emotion: tense, urgent` â†’ template with `preset_name=tense` or `fear`
- Fallback: Use character's base/neutral template if no emotion match
- Manual: User picks from dropdown of all character templates

### Screen 3: Segment Review & Render

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“ Segments (47)         [Render All]  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€ #1 narrator / warm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "The team gathered in the          â”‚  â”‚
â”‚  â”‚  observation dome..."              â”‚  â”‚
â”‚  â”‚ ðŸŽ¯ warm, clear, announcer         â”‚  â”‚
â”‚  â”‚ Template: warm-narration (Kira)    â”‚  â”‚
â”‚  â”‚ [â–¶ Play] [ðŸ”„ Re-render] [âœ Edit]  â”‚  â”‚
â”‚  â”‚ âœ… 4.2s                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€ #2 narrator / tense â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "The readings spiked without       â”‚  â”‚
â”‚  â”‚  warning..."                       â”‚  â”‚
â”‚  â”‚ ðŸŽ¯ tense, urgent, accelerating    â”‚  â”‚
â”‚  â”‚ Template: tense-urgent (Kira)      â”‚  â”‚
â”‚  â”‚ [â–¶ Render] (not rendered yet)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€ #3 maya / excited â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "The crystalline structures..."    â”‚  â”‚
â”‚  â”‚ ðŸŽ¯ warm, curious, professional    â”‚  â”‚
â”‚  â”‚ Template: [swap â–¼]  âš  No match    â”‚  â”‚
â”‚  â”‚ [â–¶ Render]                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  Progress: 12/47 rendered â”‚ 8 approved  â”‚
â”‚  [â—€ Back]           [Export Chapter â†’]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Per-segment controls:**
- **Play**: Play rendered audio
- **Re-render**: Generate new audio (same template, new TTS run â€” variations are natural)
- **Edit**: Change the text or instruct before rendering
- **Swap template**: Pick a different template for this segment
- **Approve/Reject**: Mark segment as good (âœ…) or needs redo
- **Render All**: Batch-render all unrendered segments (queued as drafts)

**Key UX decisions:**
- Segments render as **drafts** in the existing draft system â€” reuses all the queue/status/retry infrastructure
- Each segment = 1 draft, tagged with `script_id` + `segment_index` for ordering
- Rendering is incremental: render a few, listen, adjust, render more
- No forced order â€” can jump to any segment

### Screen 4: Export

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“¦ Export Chapter                      â”‚
â”‚                                         â”‚
â”‚  Chapter: "The Ice"                     â”‚
â”‚  Segments: 47/47 rendered, 47 approved  â”‚
â”‚  Duration: 8:23                         â”‚
â”‚                                         â”‚
â”‚  Format: [MP3 â–¼] Quality: [320kbps â–¼]  â”‚
â”‚  â–¡ Add 0.5s silence between segments    â”‚
â”‚  â–¡ Normalize volume across segments     â”‚
â”‚                                         â”‚
â”‚  [â¬‡ Download MP3]                       â”‚
â”‚  [ðŸ“¤ Send to Discord]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Concatenates all approved segments via ffmpeg. Options for inter-segment silence, volume normalization, format.

---

## Architecture

### New Data Models

```
Script
â”œâ”€â”€ id (UUID)
â”œâ”€â”€ user_id (FK â†’ User)
â”œâ”€â”€ title (string)
â”œâ”€â”€ raw_markdown (text)
â”œâ”€â”€ created_at
â””â”€â”€ updated_at

ScriptSegment
â”œâ”€â”€ id (UUID)
â”œâ”€â”€ script_id (FK â†’ Script)
â”œâ”€â”€ index (int) â€” ordering
â”œâ”€â”€ speaker (string) â€” from @speaker tag
â”œâ”€â”€ emotion (string) â€” from @emotion tag
â”œâ”€â”€ text (string) â€” the actual content
â”œâ”€â”€ character_id (FK â†’ Character, nullable) â€” matched character
â”œâ”€â”€ template_id (FK â†’ Template, nullable) â€” matched template
â”œâ”€â”€ draft_id (FK â†’ Draft, nullable) â€” rendered audio
â”œâ”€â”€ status: unmatched | matched | rendering | rendered | approved
â””â”€â”€ instruct_override (text, nullable) â€” manual override
```

### New API Endpoints

```
POST   /api/v1/scripts              â€” Upload & parse markdown
GET    /api/v1/scripts              â€” List scripts
GET    /api/v1/scripts/{id}         â€” Get script with segments
DELETE /api/v1/scripts/{id}         â€” Delete script

POST   /api/v1/scripts/{id}/match   â€” Auto-match segments to templates
PATCH  /api/v1/scripts/{id}/segments/{idx} â€” Override match for segment

POST   /api/v1/scripts/{id}/render  â€” Render all unrendered segments (batch)
POST   /api/v1/scripts/{id}/segments/{idx}/render â€” Render single segment
POST   /api/v1/scripts/{id}/segments/{idx}/approve â€” Mark approved

POST   /api/v1/scripts/{id}/export  â€” Concatenate & return final audio
```

### Template Matching Algorithm

```python
def match_segment(segment, character, templates):
    """Match a segment's emotion to the best template."""
    
    # 1. Exact preset name match
    for t in templates:
        if t.preset_name == segment.emotion:
            return t
    
    # 2. Fuzzy: emotion words overlap
    emotion_words = set(segment.emotion.lower().split(', '))
    best_score, best_t = 0, None
    for t in templates:
        t_words = set(t.instruct.lower().split())
        overlap = len(emotion_words & t_words)
        if overlap > best_score:
            best_score, best_t = overlap, t
    if best_t and best_score > 0:
        return best_t
    
    # 3. Fallback: neutral/calm template or first available
    for t in templates:
        if t.preset_name in ('neutral', 'calm', 'default'):
            return t
    
    return templates[0] if templates else None
```

### How Rendering Works

Two modes, depending on whether we have a clone prompt or use VoiceDesign:

**Mode A â€” VoiceDesign (current):**
Each segment renders via `POST /api/v1/voices/design` with:
- `text`: segment text
- `instruct`: `{character.base_description}, {template.instruct}`
- `language`: from script metadata

**Mode B â€” Clone Prompts (future, better quality):**
Each segment renders via clone prompt endpoint with:
- `voice_name`: from template's associated clone prompt
- `text`: segment text  
- `instruct`: emotion/direction overlay

Mode B requires the GCS prompt sync feature (not yet built). Mode A works today.

### Integration with Existing Draft System

Script rendering reuses the draft infrastructure:
- Each segment render creates a Draft record (with `script_id` + `segment_index` metadata)
- Draft queue, polling, retry all work as-is
- Templates created via the existing approve flow

New fields on Draft model:
```python
script_id: Optional[UUID]      # FK â†’ Script
segment_index: Optional[int]   # ordering within script
```

### Frontend Routes

```
/scripts                    â€” Script list
/scripts/:id                â€” Script detail (cast + segment review)
/scripts/:id/export         â€” Export page
```

### Rendering Pipeline (batch)

```
User clicks "Render All"
  â†’ POST /api/v1/scripts/{id}/render
    â†’ For each unrendered segment:
        1. Look up matched template
        2. Build instruct = base_description + template.instruct + emotion_override
        3. Create Draft with script_id, segment_index
        4. Queue TTS job (background task, same as draft system)
    â†’ Return { queued: N }
  â†’ Frontend polls draft list filtered by script_id
  â†’ Segments update as drafts complete
```

### Scalability: Full Novel

For a full novel (~20 chapters Ã— ~50 segments = 1000 segments):
- **Script list page** shows chapters with progress bars
- **Batch operations**: "Render All Chapters" queues everything
- **Resume**: Pick up where you left off â€” only unrendered segments queue
- **Consistent voices**: Once cast, all chapters use the same templates
- **Project-level casting**: Define voice cast once, apply to all chapters

Could add a `Project` model above `Script` for this:
```
Project â†’ [Script, Script, ...] â†’ [Segment, Segment, ...]
         â†“
       VoiceCast (speakerâ†’character+default_template mapping)
```

---

## Implementation Phases

### Phase 1: Core (1 sprint, ~13pts)
- Script model + CRUD endpoints
- Markdown parser (reuse from render_qwen.py)
- Segment model with manual template assignment
- Basic segment list UI
- Single-segment render (creates Draft)
- Play/retry per segment

### Phase 2: Smart Matching (1 sprint)
- Auto-match algorithm
- Cast UI (speaker â†’ character â†’ template mapping)
- Batch render
- Segment approval workflow

### Phase 3: Export (half sprint)
- ffmpeg concatenation endpoint
- Export UI with format/quality options
- Download + Discord send

### Phase 4: Novel Scale (1 sprint)
- Project model (groups chapters)
- Project-level voice cast
- Batch chapter rendering
- Progress dashboard

---

## Open Questions

1. **Should we support re-ordering segments in the UI?** (Probably not â€” trust the script order)
2. **Should we edit the markdown source or just override per-segment?** (Override â€” keep source immutable)
3. **How to handle segment chunking?** (500-char chunks from render_qwen.py â€” expose as sub-segments or hide?)
4. **Cross-segment consistency?** (Same speaker+emotion should sound similar â€” templates help, but TTS is stochastic)
5. **Version control on scripts?** (Re-upload overwrites? Or keep history?) 
